{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Discrete, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from DQN_Agent import *\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(101)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(101)\n",
    "    torch.cuda.manual_seed_all(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/kaggle/input/aapl-quotes-data/AAPL_Quotes_Data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing training data, fitler date with less than 390 mins\n",
    "data[\"date\"] = data[\"timestamp\"].apply(lambda x: x.split(\" \")[0])\n",
    "num_minutes_each_date = data.groupby(\"date\").count()[\"timestamp\"]\n",
    "valid_date = num_minutes_each_date[num_minutes_each_date == 390].index.tolist()\n",
    "data = data[data[\"date\"].isin(valid_date)].reset_index().drop([\"date\", \"index\"], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of date\n",
    "data.shape[0] // 390\n",
    "# Use last 8 dates in the data as testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We first try to work on default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TradingEnv(1000, 390, 35, data, True)\n",
    "agent_params = {\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "# Train the DQN agent\n",
    "agent = create_and_train_dqn(agent_params, env, num_episodes = 40)\n",
    "\n",
    "agent.save_agent_model(\"agent_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TradingEnv(1000, 390, 43, data, True)\n",
    "res = pd.DataFrame(columns = [\"timestamp\", \"shares\"])\n",
    "for i in range(35, 43):\n",
    "    env.reset()\n",
    "    env.set_current_date(i)\n",
    "    curr_res, _ = get_best_actions(agent, env, i)\n",
    "    res = pd.concat([res, curr_res])\n",
    "res.to_csv(\"data\\default_dqn_trades.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we try to conduct using bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(gamma: float, epsilon: float, epsilon_decay, lr: float):\n",
    "    # Train the agent\n",
    "    agent = DQNAgent(device, 390, 1001, gamma = gamma, epsilon = epsilon, epsilon_decay = epsilon_decay, lr = lr)\n",
    "    env = TradingEnv(num_shares = 1000, num_time_units = 390, num_date = 28, data = data) # among the 35 episode used, 7 of them used in test\n",
    "    agent = train_dqn(agent, env)\n",
    "    # Use the agent on the last 7 days\n",
    "    total_rewards_all = 0\n",
    "    for i in range(28, 35):\n",
    "        env.reset()\n",
    "        env.set_current_date(i)\n",
    "        _, total_rewards = get_best_actions(agent, env)\n",
    "        total_rewards_all += total_rewards\n",
    "    print(f\"Finish trial {gamma}, {epsilon}, {epsilon_decay}, {lr} with rewards: {total_rewards}\")\n",
    "    return total_rewards_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_model = GaussianProcessRegressor()\n",
    "# surrogate function or approx for objective function using a Gaussian Process\n",
    "def surrogate(params):\n",
    "    return surrogate_model.predict(params, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the acquisition function to get the next point\n",
    "def acquisition(possible_params_new):\n",
    "    curr_max = np.max(surrogate(params_used))\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    obj_new_mean, obj_new_std = surrogate(possible_params_new)\n",
    "    # calculate the probability of improvement\n",
    "    probs = norm.cdf((obj_new_mean - curr_max) / (obj_new_std+1E-9))\n",
    "    return probs\n",
    "\n",
    "# now we optimize the acquisition function with random search\n",
    "def optimize_acquisition(rng):\n",
    "    # Explore some possible choice\n",
    "    possible_gamma = rng.uniform(0, 1, size = (1000,1))\n",
    "    possible_epsilon = rng.uniform(0, 1, size = (1000,1))\n",
    "    possible_epsilon_decay = rng.uniform(0.7, 1, size = (1000,1))\n",
    "    possible_learning_rate = rng.choice([0.001, 0.003, 0.01, 0.05, 0.1], size = (1000,1))\n",
    "    possible_params_new = np.hstack((possible_gamma, possible_epsilon, possible_epsilon_decay, possible_learning_rate))\n",
    "    \n",
    "    # Calculate acquisition score\n",
    "    scores = acquisition(possible_params_new)\n",
    "    \n",
    "    # get the max score and return as new found X\n",
    "    return possible_params_new[np.argmax(scores), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we conduct Bayesian Optimization\n",
    "params_used = np.zeros((0, 4))\n",
    "obj_used = np.zeros((0, 1))\n",
    "\n",
    "# Default rng\n",
    "rng = np.random.default_rng(seed = 101)\n",
    "\n",
    "# Number of BO trials:\n",
    "n_trials = 15\n",
    "\n",
    "# Start with some exploration trials:\n",
    "n_explore_trials = 5\n",
    "\n",
    "for i in range(n_trials + n_explore_trials):\n",
    "    if i < n_explore_trials:\n",
    "        # exploration steps\n",
    "        gamma_new = rng.uniform(0, 1)\n",
    "        epsilon_new = rng.uniform(0, 1)\n",
    "        epsilon_decay_new = rng.uniform(0.7, 1)\n",
    "        learning_rate_new = rng.choice([0.001, 0.003, 0.01, 0.05, 0.1])\n",
    "        params_new = np.array([gamma_new, epsilon_new, epsilon_decay_new, learning_rate_new])\n",
    "        obj_new = objective(gamma_new, epsilon_new, epsilon_decay_new, learning_rate_new)\n",
    "    else:\n",
    "        # Find next training point\n",
    "        params_new = optimize_acquisition(rng)\n",
    "        obj_new = objective(*params_new)\n",
    "    \n",
    "    # Train the surrogate model\n",
    "    params_used = np.vstack((params_used, params_new.reshape((1, 4))))\n",
    "    obj_used = np.vstack((obj_used, np.array([obj_new]).reshape((1, 1))))\n",
    "    surrogate_model.fit(params_used, obj_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params_used[np.argmax(obj_used), :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
